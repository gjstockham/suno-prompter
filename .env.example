# Choose your default provider (openai or azure)
LLM_PROVIDER=openai

# OpenAI-compatible API Configuration
OPENAI_CHAT_MODEL_ID=gpt-4o
OPENAI_API_KEY=your-api-key-here
# For custom endpoints (Ollama, LM Studio, etc.): Set base URL
# OPENAI_BASE_URL=http://localhost:11434/v1

# Azure OpenAI Configuration (deployment-based)
# AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/
# AZURE_OPENAI_API_KEY=your-api-key-here
# AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment
# AZURE_OPENAI_MODEL_ID=gpt-4o  # optional, some setups expose this

# Optional per-agent overrides
# TEMPLATE_LLM_PROVIDER=azure
# TEMPLATE_AZURE_DEPLOYMENT_NAME=lyric-template-deployment
# WRITER_CHAT_MODEL_ID=gpt-4o-mini
# REVIEWER_CHAT_MODEL_ID=gpt-4o
# PRODUCER_LLM_PROVIDER=openai

# Application Settings (optional)
LOG_LEVEL=INFO
APP_DEBUG=false
# PORT=5000
# FLASK_DEBUG=false
